# ðŸ“˜ ML-Maths

**A comprehensive guide covering foundational and advanced mathematical concepts, linear algebra, multivariable calculus, probability, and machine learning applications.**

---

## ðŸ“‚ Contents

### 1. Preliminaries

#### 1.1 Introduction to Set Theory
- 1.1.1 Special Sets  
- 1.1.2 Statements and Predicates  
- 1.1.3 Equivalent Sets  
- 1.1.4 The Constructive Definition of a Set  
- 1.1.5 The Conditional Definition of a Set  
- 1.1.6 Describing Sets Using Set-Builder Notation  
- 1.1.7 Describing Planar Regions Using Set-Builder Notation  
- 1.1.8 Subsets  

#### 1.2 Set Operations
- 1.2.1 The Difference of Sets  
- 1.2.2 Set Complements  
- 1.2.3 The Cartesian Product  
- 1.2.4 Visualizing Cartesian Products  
- 1.2.5 Indexed Sets  
- 1.2.6 Sets and Functions  

#### 1.3 Properties of Sets
- 1.3.1 Cardinality of Finite Sets  
- 1.3.2 Infinite Sets  
- 1.3.3 Interior and Boundary Points  
- 1.3.4 Interiors and Boundaries of Sets  
- 1.3.5 Open and Closed Sets  

#### 1.4 Vector Geometry
- 1.4.1 The Vector Equation of a Line  
- 1.4.2 The Parametric Equations of a Line  
- 1.4.3 The Cartesian Equation of a Line  
- 1.4.4 The Vector Equation of a Plane  
- 1.4.5 The Cartesian Equation of a Plane  
- 1.4.6 The Parametric Equations of a Plane  
- 1.4.7 The Intersection of Two Planes  

#### 1.5 The Hyperbolic Functions
- 1.5.1 The Hyperbolic Functions  
- 1.5.2 Graphs of the Hyperbolic Functions  

---

### 2. Matrices

#### 2.6 Determinants
- 2.6.1 The Determinant of an NxN Matrix  
- 2.6.2 Finding Determinants Using Laplace Expansions  
- 2.6.3 Basic Properties of Determinants  
- 2.6.4 Further Properties of Determinants  
- 2.6.5 Row and Column Operations on Determinants  
- 2.6.6 Conditions When a Determinant Equals Zero  

#### 2.7 Gaussian Elimination
- 2.7.1 Systems of Equations as Augmented Matrices  
- 2.7.2 Row Echelon Form  
- 2.7.3 Solving Systems of Equations Using Back Substitution  
- 2.7.4 Elementary Row Operations  
- 2.7.5 Creating Rows or Columns Containing Zeros Using Gaussian Elimination  
- 2.7.6 Solving 2x2 Systems of Equations Using Gaussian Elimination  
- 2.7.7 Solving 2x2 Singular Systems of Equations Using Gaussian Elimination  
- 2.7.8 Solving 3x3 Systems of Equations Using Gaussian Elimination  
- 2.7.9 Identifying the Pivot Columns of a Matrix  
- 2.7.10 Solving 3x3 Singular Systems of Equations Using Gaussian Elimination  
- 2.7.11 Reduced Row Echelon Form  
- 2.7.12 Gaussian Elimination For NxM Systems of Equations  

#### 2.8 The Inverse of a Matrix
- 2.8.1 Finding the Inverse of a 2x2 Matrix Using Row Operations  
- 2.8.2 Finding the Inverse of a 3x3 Matrix Using Row Operations  
- 2.8.3 Matrices With Easy-to-Find Inverses  
- 2.8.4 The Invertible Matrix Theorem in Terms of 2x2 Systems of Equations  
- 2.8.5 Triangular Matrices  

#### 2.9 Affine Transformations
- 2.9.1 Affine Transformations  
- 2.9.2 The Image of an Affine Transformation  
- 2.9.3 The Inverse of an Affine Transformation  

---

### 3. Vector Spaces

#### 3.10 Vectors in N-Dimensional Space
- 3.10.1 Vectors in N-Dimensional Euclidean Space  
- 3.10.2 Linear Combinations of Vectors  
- 3.10.3 Linear Span  
- 3.10.4 Linear Dependence and Independence  

#### 3.11 Subspaces
- 3.11.1 Subspaces of N-Dimensional Space  
- 3.11.2 Geometric Interpretation  
- 3.11.3 Column Space  
- 3.11.4 Null Space  

#### 3.12 Bases
- 3.12.1 Finding a Basis of a Span  
- 3.12.2 Basis of Column Space  
- 3.12.3 Basis of Null Space  
- 3.12.4 Coordinates in a Given Basis  
- 3.12.5 Writing Vectors in Different Bases  
- 3.12.6 Change-of-Coordinates Matrix  
- 3.12.7 Changing a Basis  

#### 3.13 Dimension and Rank
- 3.13.1 Dimension of a Span  
- 3.13.2 Rank of a Matrix  
- 3.13.3 Dimension of Null Space  
- 3.13.4 Invertible Matrix Theorem  
- 3.13.5 Rank-Nullity Theorem  

---

### 4. Diagonalization of Matrices

#### 4.14 Eigenvectors and Eigenvalues
- 4.14.1 Eigenvalues & Eigenvectors (2x2)  
- 4.14.2 Calculating Eigenvalues (2x2)  
- 4.14.3 Calculating Eigenvectors (2x2)  
- 4.14.4 Characteristic Equation  
- 4.14.5 Eigenvectors (3x3 Distinct)  
- 4.14.6 Eigenvectors (3x3 General Case)  

#### 4.15 Diagonalization
- 4.15.1 Diagonalizing a 2x2 Matrix  
- 4.15.2 Diagonalizing a 3x3 Matrix (Distinct)  
- 4.15.3 Diagonalizing a 3x3 Matrix (General)  
- 4.15.4 Symmetric Matrices  
- 4.15.5 Diagonalization of Symmetric Matrices (2x2, 3x3)  

---

### 5. Orthogonality & Projections

#### 5.16 Inner Products
- 5.16.1 Dot Product  
- 5.16.2 Norm of a Vector  
- 5.16.3 Introduction to Abstract Vector Spaces  
- 5.16.4 Defining Abstract Vector Spaces  
- 5.16.5 Inner Product Spaces  

#### 5.17 Orthogonality
- 5.17.1 Orthogonal Vectors  
- 5.17.2 Cauchy-Schwarz Inequality  
- 5.17.3 Orthogonal Complements  
- 5.17.4 Orthogonal Sets  
- 5.17.5 Orthogonal Matrices  
- 5.17.6 Orthogonal Linear Transformations  

#### 5.18 Orthogonal Projections
- 5.18.1 Projecting onto 1D Subspaces  
- 5.18.2 Components in Orthogonal Bases  
- 5.18.3 Projecting onto Subspaces (Orthogonal)  
- 5.18.4 Projecting onto Subspaces (Arbitrary)  
- 5.18.5 Applications  
- 5.18.6 Gram-Schmidt Process  

---

### 6. Singular Value Decomposition

#### 6.19 Quadratic Forms
- 6.19.1 Bilinear Forms  
- 6.19.2 Quadratic Forms  
- 6.19.3 Change of Variables  
- 6.19.4 Positive/Negative Definite Forms  
- 6.19.5 Constrained Optimization  
- 6.19.6 Where Extrema Are Attained  

#### 6.20 SVD
- 6.20.1 Singular Values  
- 6.20.2 Computing Singular Values  
- 6.20.3 SVD for 2x2 Matrices  
- 6.20.4 SVD with Zero or Repeated Eigenvalues  
- 6.20.5 SVD of Larger Matrices  
- 6.20.6 Pseudoinverse via SVD  

---

### 7. Applications of Linear Algebra

#### 7.21 Principal Component Analysis
- 7.21.1 Introduction  
- 7.21.2 Computing Principal Components  
- 7.21.3 PCA & SVD Connection  

#### 7.22 Linear Least-Squares
- 7.22.1 Without Collinearity  
- 7.22.2 With Collinearity  

#### 7.23 Linear Regression
- 7.23.1 Linear Regression  
- 7.23.2 Polynomial Regression  
- 7.23.3 Multiple Linear Regression  

---

### 8. Multivariable Calculus

#### 8.24 Quadric Surfaces & Cylinders
- 8.24.1â€“8.24.6 Ellipsoids, Hyperboloids, Paraboloids, Cones, Cylinders  

#### 8.25 Partial Derivatives
- Domain, Level Curves, Continuity  
- Partial Derivatives, Higher Order  
- Tangent Planes, Chain Rule  

#### 8.26 Vector-Valued Functions
- Domains, Tangents, Gradients, Directional Derivatives  

#### 8.27 Differentiation
- Jacobian, Inverse Function Theorem  
- Derivatives and Taylor Polynomials  

#### 8.28 Riemann Sums
- Lower/Upper Approximations  
- General Rectangular Partitions  

#### 8.29 Double Integrals
- Rectangular and Non-Rectangular Domains  
- Type I & II Regions  

---

### 9. Probability & Random Variables

#### 9.30â€“9.31 Basics
- Probability Rules, Bayesâ€™ Theorem  
- Continuous Random Variables  

#### 9.32â€“9.33 Transformations & Expectation
- Discrete & Continuous Transformations  
- Expected Value, Variance, Moments  

#### 9.34 Discrete Distributions
- Bernoulli, Binomial, Poisson, Uniform  

#### 9.35 Continuous Distributions
- Uniform, Gamma, Chi-Square, T-Distribution, Exponential  

---

### 10. Combining Random Variables

- Joint, Marginal, Conditional Distributions  
- Covariance & Correlation  
- Normal Distributions and Combinations  

---

### 11. Parametric Inference

- Point Estimation  
- Maximum Likelihood Estimation  
- Hypothesis Testing  
- Confidence Intervals  

---

> ðŸ“Œ *This document serves as an extensive reference for foundational mathematics, statistics, and machine learning applications. Useful for students, educators, and practitioners alike.*

